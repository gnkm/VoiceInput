# AGENTS.md

このファイルは、VoiceInputプロジェクトに参加するAIエージェント（あなた）のための決定的なガイドです。
コードを変更したり提案したりする前に、必ずこのドキュメントを読んでください。

## 🛑 最重要ルール

**[CONTRIBUTING.md](./CONTRIBUTING.md) の内容は絶対です。**

あなたが提案するすべての変更は、`CONTRIBUTING.md` に記載されたルール（ブランチ戦略、コミットメッセージ、Lint/Test）に準拠している必要があります。

### クイックチェックリスト (詳細は CONTRIBUTING.md を参照)

1.  **ブランチ名**: `type/description` 形式 (例: `feature/add-settings`, `fix/hotkey-bug`)
    -   `feature/`: 新機能
    -   `fix/`: バグ修正
    -   `refactor/`: リファクタリング
    -   `docs/`: ドキュメント
    -   `test/`: テスト
    -   `chore/`: その他
2.  **コミットメッセージ**: Conventional Commits 形式 (例: `feat(ui): add settings page`)
3.  **事前チェック**: 以下のコマンドがエラーなく通ることを保証してください。
    -   `flutter analyze`
    -   `dart format .`
    -   `flutter test`

---

## 🎯 プロジェクトのゴールと制約

VoiceInputは、**プライバシーファースト**かつ**ローカル完結型**の音声入力ユーティリティです。

### 絶対に守るべき制約 (Non-negotiables)

1.  **外部通信の禁止**: 音声データやテキストデータを外部サーバー（OpenAI APIなど）に送信してはいけません。すべての処理はローカルで行われます。(REQ-PRIV-001)
2.  **クロスプラットフォーム**: Windows, macOS, Linux すべてで動作することを前提にコードを書いてください。特定のOSに依存する機能は、必ずプラットフォームチェックを行うか、抽象化レイヤーを通じて実装してください。
3.  **バックグラウンド指向**: アプリは主にバックグラウンド（システムトレイ）で動作します。ウィンドウは必要な時（設定など）だけ表示されます。

## 🛠 技術スタックと実装方針

-   **言語/フレームワーク**: Dart / Flutter
-   **音声認識**: OpenAI Whisper のローカル実行
    -   推論はCPU/GPUを用いてローカルで行います。
-   **ホットキー**: グローバルホットキーの監視が必要。
-   **テキスト入力**: OSレベルでのテキスト挿入（キーボードイベントのシミュレーションやクリップボード操作）。

## 📂 ディレクトリ構造の歩き方

-   `lib/`: FlutterのDartコード。UIとビジネスロジック。
-   `macos/`, `windows/`, `linux/`: プラットフォーム固有のランナーとネイティブコード。
-   `docs/`: 要件定義 (`requirements.md`) と技術スタック (`tech_stack.md`)。**仕様に迷ったらここを読んでください。**
-   `test/`: テストコード。

## 🤖 エージェントへの行動指針

1.  **文脈を読む**: ユーザーの曖昧な指示に対しては、プロジェクトのゴール（ローカル、プライバシー、効率）に照らし合わせて最適な解釈を行ってください。
2.  **小さく作る**: 巨大な変更を一度に行わず、検証可能な小さな単位で実装・提案してください。
3.  **既存コードの尊重**: 既存の設計パターンや命名規則に従ってください。
4.  **自己修正**: コードを生成した後は、必ずLintやFormatの適用を考慮してください。

---

このドキュメントは、あなたが迷ったときの道標です。開発を始める前に [CONTRIBUTING.md](./CONTRIBUTING.md) を確認しましたか？

